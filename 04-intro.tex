

\polish{Expand to describe importance, severity, and prevalence of the issues you are addressing.}
\polish{Way to expand: Add a statement/section about who the intended users of the systems are? -- statistically conversant, domain experts, limited statistical expertise}


Statistical analysis plays a critical role in how people evaluate data and make
decisions. Policy makers rely on models to track disease, inform health
recommendations, and allocate resources. Scientists develop, evaluate, and
compare theories based on statistical results. Journalists report on new
findings in science, which individuals use to make decisions that impact their
nutrition, finances, and other aspects of their lives. Faulty statistical models
can lead to spurious estimations, findings that do not generalize or reproduce,
and a misinformed public. 

Despite the prevalence of statistical analyses and their central importance to a
number of disciplines, they remain challenging to author accurately. The key
challenge in developing accurate statistical models lies not in a lack of access
to computational tools, of which there are many (e.g., R~\cite{team2013r},
Python~\cite{sanner1999python}, SPSS~\cite{spss}, and SAS~\cite{sas}), but in
accurately applying them in conjunction with domain theory, data collection,
statistical knowledge, and programming ability~\cite{mcelreath2020statistical}.
Analysts must translate their implicit domain knowledge into statistical models
that they can then implement and execute in code. However, this process---which
requires disciplinary, statistical, and programming expertise---is out of reach
for statistical non-experts who depend on accurate analyses, including many
researchers. 
% This process requires
% expertise in a discipline, statistics, and programming.
% Analysts must integrate multiple knowledge sources to specify statistical
% analyses. Yet, this integrative process is out of reach for statistical
% non-experts who depend on accurate analyses, including many researchers. 


\section{Thesis Approach and Statement}
This dissertation asks if separating the above concerns and incorporating
automated reasoning in statistical software could benefit statistical
non-experts. Towards this goal, I combine techniques from human-computer
interaction, programming languages/software engineering, and statistics to (i)
characterize the cognitive and operational steps to author statistical analyses
and (ii) develop novel interactive systems that enable statistical non-experts
to author valid analyses. As detailed below, I not only move between systems
building and empirical studies but use each to deepen and enhance the other.

The work described in this dissertation demonstrates the following:% thesis statement: 
\addcontentsline{toc}{section}{Thesis statement}
\paragraph{Thesis statement} \label{para:thesisStatement}
% Centered on the insight that domain experts using statistical methods are
% focused on their domain 

%%% COULD MAKE THIS STRONGER?
% Domain-specific languages that provide abstractions for expressing conceptual
% knowledge, data collection procedures, and analysis intents instead of specific
% statistical modeling decisions coupled with automated reasoning to compile
% conceptual specifications into statistical analysis code help statistical
% non-experts more readily author valid analyses. 

% Statistical non-experts can more readily author valid analyses using a
% combination of domain-specific languages (DSL) and automated reasoning. Rather
% than specify statistical modeling decisions directly, analysis DSLs can express
% conceptual knowledge, data collection procedures, and analysis intents.
% Automated reasoning methods can then compile conceptual DSL specifications into
% statistical analysis code.

A combination of domain-specific languages (DSLs) and automated reasoning can
help statistical non-experts more readily author valid analyses. Analysis DSLs
express conceptual knowledge, data collection procedures, and
analysis intents. Automated reasoning methods then compile the conceptual
DSL specifications into statistical analysis code.

% Rather than
% directly specifying statistical modeling decisions, analysis 

Three challenges fall out of this thesis statement: 

\addcontentsline{toc}{subsection}{Challenge 1}
\section*{Challenge 1: How to make implicit domain knowledge explicit.} %- domain knowledge
Designing abstractions focused on conceptual knowledge requires identifying what
domain knowledge analysts want and can express and then balancing these
constraints with what automated reasoning approaches may require. What is easy
to express and what is easy to assume for the sake of automation may be at odds,
especially when analysts provide ambiguous specifications that could be compiled
into multiple statistical analyses. The challenge, therefore, is to design
language constructs that are usable for analysts, useful for automated
reasoning, and support interactive program specification as necessary.

% Finding: interactive disambiguation not just necessary for refinement and automated reasoning but *useful* to analysts for reflection

% Shifting focus onto the goal/motivation of analysis and less on the details that can overwhelm and restrict analysts

% **Not just higher levels of abstraction but appropriate abstractions that allow analysts to dig deeper into the appropriate parts

\addcontentsline{toc}{subsection}{Challenge 2}
\section*{Challenge 2: Represent and reason about key statistical analysis decisions} %- programming
A central idea in this thesis is that software systems should take on the
responsibility of translating conceptual knowledge into statistical analyses.
This is akin to a compilation process that requires representing the conceptual
knowledge analysts express and reasoning over it to derive statistical
analyses that respect statistical best practices and rules. A
major challenge is in picking representations so that the reasoning is straightforward. 
% not only straightforward but also beneficial in someway (expressivity, extensibility for both Tea and Tisane)

\addcontentsline{toc}{subsection}{Challenge 3}
\section*{Challenge 3: Increase analysts' statistical knowledge/understanding} %- statistics
% connect to Bellotti on user control?
While automating statistical analysis can be helpful, analysts relying on data
to make high-impact decisions (e.g., policy, scientific discovery) often need to
understand why an analysis approach is appropriate and what the implications of
the results are to their domain. Furthermore, software can inform how users
approach future analyses. Therefore, educating analysts about the applicability
and impact of statistical decisions and guiding their interpretation of results
are important.

\section{Summary of Contributions}
This dissertation contributes principles and systems for designing data analysis
tools for statistical non-experts. The contributions can be summarized as follows: 

\begin{comment}
new domain-specific languages (DSLs),
representations, and reasoning approaches for authoring statistical analyses. Additionally, 
a new theory describing the cognitive and operational steps involved in
authoring statistical analyses. In the process of designing the second DSL, we
also explored new methods for eliciting and integrating user feedback throughout
programming language design. The content of thesis is as follows. 

This dissertation contributes new domain-specific languages (DSLs) for authoring
statistical analyses and a new theory describing the cognitive and operational
steps involved in authoring statistical analyses. In the process of designing
the second DSL, we also explored new methods for eliciting and integrating user
feedback throughout programming language design. The content of thesis is as
follows. 

Specifically, I designed and implemented two systems, Tea~\cite{jun2019tea} and
Tisane~\cite{jun2022tisane}, that leverage \textbf{domain-specific languages}
(DSLs) to capture analysts' implicit assumptions and conceptual knowledge. Users
\textbf{interactively compile} these high-level specifications into low-level
code. To infer valid statistical analyses, the systems \textbf{programmatically
represent and reason about core statistical authoring challenges} as constraints
and graphs (\autoref{fig:tools}).
% As a result, my systems prevent common analysis
% mistakes~\cite{jun2019tea,jun2022tisane}. 
\end{comment}

\begin{enumerate} 
    \item An assessment of the existing state of data analysis practice and tool support.
    \begin{enumerate}
        \item Our theory of \hypoForm describes the cognitive and operational
        steps involved in translating a high-level conceptual research question
        and hypothesis into a statistical analysis implemented in code. This
        conceptual framework is useful for explaining what support existing
        statistical tools fail to provide statistical non-experts and justifying
        the design of systems developed in this dissertation.
        \item We provide the first account scrutinizing the \hypoForm process in
        situ. Whereas previous studies of data analysis have relied on
        self-reports about analyses, we conduct an in-depth lab study where we
        observe analysts prepare and even start to implement statistical
        analyses. 
        \item We qualitatively assess 20 statistical analysis libraries and
        standalone systems in order ot understand how they structure data
        analysis authoring. Combining our theory of \hypoForm and this tools
        assessment, we develop three design implications for how data analysis
        software could better serve statistical non-experts. 
    \end{enumerate}

    \item The design, implementation, and evaluation of new DSLs. These DSLs
    explore ways to design abstractions that prioritize making implicit domain
    knowledge explicit. 
    \begin{enumerate}
        \item The \tea DSL provides a high-level API so that analysts can make
        explicit their asumptions about the data and their hypotheses to test
        using Null Hypothesis Significance Tests. 
        \item The \tisane DSL captures analysts' ``fuzzy'' assumptions about how
        variables relate in their discipline in the form of a \textit{conceptual
        model}.
        \item A formative study showed how statistical non-experts implicitly
        think about causality, how they would like to express their implicit
        assumptions, and what they expect language constructs describing
        conceptual models to mean. These findings informed the re-design of
        \tisane's DSL, release as \rTisane.
        \item Case studies and a controlled lab study demonstrate the benefit of
        these DSLs in helping analysts become more aware of their implicit
        assumptions. 
    \end{enumerate}

    \item Formal representations and automated reasoning approaches for
    statistical analysis authoring. To support statistical testing and modeling,
    we develop representations that allow automated reasoning to compile
    conceptual models into statistical models. 
    \begin{enumerate}
        \item In \tea, we implement a constraint-based model and knowledge base
        for Null Hypothesis Significance Tests. 
        \item In \tisane, we develop an intermediate graph representation to
        summarize key conceptual assumptions and data collection details.
        Importantly, a subgraph of the representation is a causal diagram useful
        for deriving statistical models formally. 
        \item Finally, we develop an interaction model for \textit{interactively
        compiling} high-level conceptual specifications into statistical models.
        % \polish{In a controlled lab study, we find that interactive compilation
        % contributes to analysts' increased awareness of their domain, data, and
        % statistics during data analysis.}
    \end{enumerate}
    % \item a \textbf{formal constraint-based model} to specify and select among
    % common Null Hypothesis Statistical Tests in Tea (see~\autoref{chapter:tea}); 
    % \item empirical findings of how authoring analyses requires integrating
    % conceptual, data, statistical, and programming expertise, which we summarize
    % in our \textbf{theory of hypothesis formalization} (see~\autoref{chapter:hypoForm}); 
    % \item an analysis of how the current statistical software ecosystem does not
    % explicitly support and may even hinder hypothesis formalization, suggesting
    % new \textbf{design opportunities and implications} (see~\autoref{chapter:hypoForm});
    % \item a \textbf{mixed-initiative approach} for ``interactively compiling''
    % linear models from conceptual and data relationships in Tisane; 
    % \item empirical \textbf{findings on researchers' implicit semantics of
    % conceptual models} (see~\autoref{chapter:tisane});
    % \item \textbf{new language constructs and interaction methods} for
    % reflecting on and refining conceptual models in a second version of Tisane,
    % which we call rTisane (see~\autoref{chapter:tisane}); and
    % \item qualitative and quantitative \textbf{results showing the benefit of
    % recording conceptual models and compiling them into statistical models} in
    % rTisane over a scaffolded workflow (see~\autoref{chapter:tisane}).
\end{enumerate}

% System --> Empirical --> System --> Empirical --> Empirical --> System --> Empirical 

\section{Thesis outline}
\autoref{chapter:relatedWork} covers related work that contextualizes the above
contributions. The remainder of the dissertation describes how through iterative
system development and empirical studies, we came to develop new domain-specific
languages (DSLs), representations, and reasoning approaches for authoring
statistical analyses.

\autoref{chapter:tea} presents \tea, a DSL and runtime system for Null
Hypothesis Significance Testing. After discussing more specific related work and
the statistical scope (\autoref{sec:relatedWorkTea}), the chapter describes a
usage scenario that illustrates how an analyst would use \tea and how it differs
from existing tools (\autoref{usageScenarioTeaTea}), discusses key design
considerations to improve statistical testing practice
(\autoref{sec:designConsiderationsTea}), describes the DSL (\autoref{sec:TeaPL})
and constraint-based runtime system (\autoref{sec:TeaRS}), evaluates \tea
against a corpus of expert test choices and a naive test selection regime
(\autoref{sec:evalTea}), and briefly discusses the limitations and opportunities
for future work (\autoref{sec:discussionTea}). The chapter concludes with a
summary of how our work on \tea furthers the thesis of this dissertation. 

\autoref{chapter:hypoForm} introduces our theory of \hypoForm. While \tea was an
exciting foray into how designing a DSL focused on capturing implicit data
assumptions and hypotheses and developing a formal model of statistical test
selection is not only feasible but also beneficial, this chapter steps back to
describe data analysis more holistically. In fact, this chapter retrospectively
justifies our design in \tea and directly informs our work on \tisane, the
following chapter. \autoref{chapter:hypoForm} starts by connecting hypothesis
formalization to characterizations of ``statistical thinking'' and situating
data analysis in the larger context of scientific discovery
(\autoref{sec:relatedWorkHypoForm}). The chapter proceeds to describing a
content analysis that sensitized us to key hypothesis formalization steps
(\autoref{sec:contentAnalysisHypoForm}), a lab study observing data analysts in
situ (\autoref{sec:labStudyHypoForm}), and a qualitative assessment of existing
statistical analysis tools (\autoref{sec:toolsAnalysis}). Based on these
empirical studies, we derive three design implications for how tools can
facilitate hypothesis formalization (\autoref{sec:implications}) and discuss
what problem solving strategies (and shortcuts) analysts employ without explicit
support for hypothesis formalization (\autoref{sec:discussionHypoForm}). This
chapter also concludes with a summary of the theory of \hypoForm informs the
thesis. 

\autoref{chapter:tisane} is the best representation of how this dissertation
grapples with an understanding of data analysis practices (i.e., \hypoForm),
statistical methods, and empirical evidence for what analysts want to express in
order to iteratively design and evaluate a DSL and interactive disambiguation
process. After covering related work and background on statistical scope
(\autoref{sec:relatedWorkTisane}), this chapter describes the first version of
the \tisane DSL (\autoref{sec:tisane}), case studies evaluating \tisane
(\autoref{sec:tisane_case_studies}), a study to refine the DSL
(\autoref{sec:exploratoryStudy}), the second major iteration released as
\rTisane (\autoref{sec:rTisane}), and a controlled lab study
(\autoref{sec:summativeEval}). The controlled lab study serves as a summative
evaluation of the key tenets of this dissertation. This chapter concludes with a
brief discussion of the key lessons learned and limitations of \tisane (and
\rTisane) and a summary of this work relates to the thesis. 

Finally, \autoref{chapter:conclusion} revisits the key challenges of the thesis
and how the projects in this dissertation address each
(\autoref{sec:discussionChallenges}) and outlines
(exciting!) challenges that remain to make data analysis approachable for
statistical non-experts and valid by design (\autoref{sec:futureWork}). 

% , discusses recent developments
% (\autoref{sec:recentDevelopments}), touches on the impact the systems in this
% dissertation has had in the real-world (\autoref{sec:label}),

\begin{comment}
\todo{Fill in this outline}

\section*{How to approach this dissertation} \todo{Decide if want to keep}

\section{Prior Publication and Authorship} \todo{fill in}
\end{comment}