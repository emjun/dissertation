% \polish{Expand to describe importance, severity, and prevalence of the issues you are addressing.}
% \polish{Way to expand: Add a statement/section about who the intended users of the systems are? -- statistically conversant, domain experts, limited statistical expertise}

% Prevalence
Statistical analysis plays a critical role in how people make decisions. Policy
makers rely on models to track disease, inform health recommendations, and
allocate resources. Scientists develop, evaluate, and compare theories based on
data. Journalists report on new findings in science, which
individuals use to inform decisions that impact their nutrition, finances, and
other aspects of their lives. Faulty statistical models can lead to spurious
estimations, findings that do not generalize or reproduce, and a misinformed
public. 

% Add more to severity and importance 

In the context of scientific research, accurate statistical analyses are
essential to scientific reproducibility. In a 2016 Nature survey, 1,500
identified ``selective reporting'', ``pressure to publish,'' and ``low
statistical power or poor analysis'' as the top three contributors to the
reproducibility crises in their disciplines~\cite{baker2016NatureSurvey}. The
scientists also articulated that a ``better understanding of statistics'' would
be the best approach to improve reproducibility~\cite{baker2016NatureSurvey}. 

Despite the prevalence and central importance of statistical analyses, they
remain challenging to author accurately. Key to analysis authoring is grappling
with and translating implicit domain knowledge into statistical models
executable in code~\cite{wild1999statisticalThinking,carver2016guidelines}. This
dissertation hypothesizes that better understanding and supporting this
translation process can enable statistical non-experts to author analyses
accurately. 
%  (i) probes into how and why this translation process is difficult for
% statistical non-experts and (ii) develops new computational tools that
% support this process. 

% Want to include this but IDK where:
% Translation requires disciplinary, statistical, and programming expertise is out
% of reach for many researchers and other statistical non-experts. Yet,
% statistical non-experts statistical, and programming expertise is out of reach
% for many researchers and other statistical non-experts.

% Analysts must not only organize but also translate their implicit domain
% knowledge into statistical models that they can then implement and execute in
% code.

% This dissertation probes into what
% makes authoring difficult and posits that new computational tools can enable
% statistical non-experts author analyses accurately. 


% attention to how analysts grapple with
% multiple concerns and integrate them ....

% Prior work has found a gap in the tools that people have available to use:
% Existing statistical analysis tools are either designed for students learning
% basic statistics or statistical experts~\cite{mcnamara2015bridging}. 

% Analysts must not only organize but also translate their implicit domain
% knowledge into statistical models that they can then implement and execute in
% code. Grappling with multiple concerns and integrating them into a statistical
% model is central to statistical thinking and
% practice~\cite{wild1999statisticalThinking}. However, possessing disciplinary,
% statistical, and programming expertise is out of reach for many researchers and
% other statistical non-experts. 


% The key challenge in developing
% accurate statistical models lies not in a lack of access to computational tools,
% of which there are many (e.g., R~\cite{team2013r},
% Python~\cite{sanner1999python}, SPSS~\cite{spss}, and SAS~\cite{sas}), but in
% applying them in conjunction with domain theory, data collection details,
% statistical knowledge, and programming ability~\cite{mcelreath2020statistical}.
% Analysts must not only organize but also translate their implicit domain
% knowledge into statistical models that they can then implement and execute in
% code. Grappling with multiple concerns and integrating them into a statistical
% model is central to statistical thinking and
% practice~\cite{wild1999statisticalThinking}. However, possessing disciplinary,
% statistical, and programming expertise is out of reach for many researchers and
% other statistical non-experts. 

% Even if statistical non-experts are able to move between domain and statistical
% concerns, e

% Existing statistical analysis tools are either designed for students learning
% basic statistics or statistical experts~\cite{mcnamara2015bridging}.
% Tools do
% not support statistical non-experts, such as researchers, through the process of
% authoring accurate statistical models. 

% not designed to support
% analysts through the translation process. For instance, R, a primary programming
% language of statistical analysis, was designed by and for statisticians~\cite{}.

% Given that people from diverse statistical backgrounds will only continue to
% author analyses to inform decision-making~\cite{}, understanding what makes
% statistical analyses difficult to author and addressing these challenges in
% computational tools is crucial. This dissertation addresses both of these
% concerns. 

% This process requires
% expertise in a discipline, statistics, and programming.
% Analysts must integrate multiple knowledge sources to specify statistical
% analyses. Yet, this integrative process is out of reach for statistical
% non-experts who depend on accurate analyses, including many researchers. 

% Indeed, statistical non-experts are an appropriate and promising group of
% end-users to target/design for in this dissertation. 

\begin{comment}
One naive approach....
The naive approach would be to provide analysts with software that automatically tells them which analyses to use.

But that approach is not enough. Therefore, we should look at fundamentally
changing how we write code -- evolution vs. revolution? 
\end{comment}

\section{Thesis Approach and Statement}
% This dissertation (i) characterizes the cognitive and operational steps to author
% statistical analyses and (ii) develops novel interactive systems that enable
% statistical non-experts to author valid analyses. As detailed below, I not only


This dissertation (i) probes into how and why translating domain knowledge into
executable statistical models in code is difficult and (ii) develops new
computational tools that help statistical non-experts author valid analyes by
integrating disciplinary, statistical, and programming details. Moving between
building systems and empirically studying analysts, this dissertation
demonstrates the following:% thesis statement: 
\addcontentsline{toc}{subsection}{Thesis Statement}
\paragraph{Thesis Statement} \label{para:thesisStatement}
% Centered on the insight that domain experts using statistical methods are
% focused on their domain 

%%% COULD MAKE THIS STRONGER?
% Domain-specific languages that provide abstractions for expressing conceptual
% knowledge, data collection procedures, and analysis intents instead of specific
% statistical modeling decisions coupled with automated reasoning to compile
% conceptual specifications into statistical analysis code help statistical
% non-experts more readily author valid analyses. 

% Statistical non-experts can more readily author valid analyses using a
% combination of domain-specific languages (DSL) and automated reasoning. Rather
% than specify statistical modeling decisions directly, analysis DSLs can express
% conceptual knowledge, data collection procedures, and analysis intents.
% Automated reasoning methods can then compile conceptual DSL specifications into
% statistical analysis code.

A combination of domain-specific languages (DSLs) and automated reasoning can
help statistical non-experts more readily author valid analyses. Analysis DSLs
express conceptual knowledge, data collection procedures, and
analysis intents. Automated reasoning methods then compile the conceptual
DSL specifications into statistical analysis code.

% Rather than
% directly specifying statistical modeling decisions, analysis 

The following three challenges fall out of this thesis statement.

\addcontentsline{toc}{subsection}{Challenge 1}
\def\thesisChallengeExplicit{\textbf{Thesis Challenge 1: Explicating domain knowledge}}
\paragraph{Challenge 1: Make implicit domain knowledge explicit} %- domain knowledge
Designing abstractions focused on conceptual knowledge requires identifying what
domain knowledge analysts want and can express and then balancing these
constraints with what automated reasoning approaches may require. What is easy
to express and what is easy to assume for the sake of automation may be at odds,
especially when analysts provide ambiguous specifications that could be compiled
into multiple statistical analyses. The challenge, therefore, is to design
language constructs that are usable for analysts and useful for automated
reasoning, leveraging interactive program specification as necessary.

% Finding: interactive disambiguation not just necessary for refinement and automated reasoning but *useful* to analysts for reflection

% Shifting focus onto the goal/motivation of analysis and less on the details that can overwhelm and restrict analysts

% **Not just higher levels of abstraction but appropriate abstractions that allow analysts to dig deeper into the appropriate parts

\addcontentsline{toc}{subsection}{Challenge 2}
\def\thesisChallengeRep{\textbf{Thesis Challenge 2: Representation and automated reasoning}}
\paragraph{Challenge 2: Represent and reason about key statistical analysis decisions} %- programming
A central idea in this thesis is that software systems should take on the
responsibility of translating conceptual knowledge into statistical analyses.
This is akin to representing the conceptual knowledge analysts express and
compiling it to statistical analyses that respect statistical best practices and
rules. To achieve this, selecting representations that lend themselves to
elegant reasoning methods is a technical challenge.
% not only straightforward but also beneficial in someway (expressivity, extensibility for both Tea and Tisane)

\addcontentsline{toc}{subsection}{Challenge 3}
\def\thesisChallengeUnderstanding{\textbf{Thesis Challenge 3: Statistical understanding}}
\paragraph{Challenge 3: Increase analysts' statistical understanding} %- statistics
% connect to Bellotti on user control?
While automating statistical analysis can be helpful, analysts relying on data
to make high-impact decisions (e.g., policy, scientific discovery) often need to
understand why an analysis approach is appropriate and what the implications of
the results are to their domain. Furthermore, software can inform how users
approach future analyses. Therefore, educating analysts about the applicability
and impact of statistical decisions and guiding their interpretation of results
are important.

\section{Summary of contributions}
This dissertation contributes principles and systems for designing statistical analysis
tools for statistical non-experts. The contributions can be summarized as follows: 

\begin{comment}
new domain-specific languages (DSLs),
representations, and reasoning approaches for authoring statistical analyses. Additionally, 
a new theory describing the cognitive and operational steps involved in
authoring statistical analyses. In the process of designing the second DSL, we
also explored new methods for eliciting and integrating user feedback throughout
programming language design. The content of thesis is as follows. 

This dissertation contributes new domain-specific languages (DSLs) for authoring
statistical analyses and a new theory describing the cognitive and operational
steps involved in authoring statistical analyses. In the process of designing
the second DSL, we also explored new methods for eliciting and integrating user
feedback throughout programming language design. The content of thesis is as
follows. 

Specifically, I designed and implemented two systems, Tea~\cite{jun2019tea} and
Tisane~\cite{jun2022tisane}, that leverage \textbf{domain-specific languages}
(DSLs) to capture analysts' implicit assumptions and conceptual knowledge. Users
\textbf{interactively compile} these high-level specifications into low-level
code. To infer valid statistical analyses, the systems \textbf{programmatically
represent and reason about core statistical authoring challenges} as constraints
and graphs (\autoref{fig:tools}).
% As a result, my systems prevent common analysis
% mistakes~\cite{jun2019tea,jun2022tisane}. 
\end{comment}

\begin{enumerate} 
    \item A conceptual framework characterizing statistical analysis authoring.
    \begin{enumerate}
        \item Our theory of \hypoForm describes the cognitive and operational
        steps involved in translating a high-level conceptual research question
        and hypothesis into a statistical analysis implemented in code.
        \HypoForm explains why existing statistical
        tools fail to support statistical non-experts and informs the design
        of systems developed in this dissertation.
        \item We provide the first account scrutinizing the \hypoForm process in
        situ. Whereas previous studies of data analysis have relied on
        self-reports about analysis processes, we conduct an in-depth lab study where we
        observe analysts prepare and even start to implement statistical
        models firsthand. 
        \item We qualitatively assess 20 statistical analysis libraries and
        standalone systems and illustrate how their designs represent the
        current ecosystem of statistical tools and presently influence data
        analysis practice. Furthermore, combining our theory of \hypoForm and
        this assessment of tools, we develop three design implications for how
        data analysis software could better serve statistical non-experts. 
    \end{enumerate}

    \item The design, implementation, and evaluation of new DSLs. These DSLs
    explore ways to design abstractions that prioritize making implicit domain
    knowledge explicit. 
    \begin{enumerate}
        \item The \tea DSL provides a high-level API so that analysts can make
        explicit their asumptions about the data and their hypotheses to assess
        using Null Hypothesis Significance Tests. 
        \item The \tisane DSL captures analysts' ``fuzzy'' assumptions about how
        variables relate in their discipline. The variables and relationships
        comprise a \textit{conceptual model}.
        \item An exploratory elicitation study showed how statistical non-experts implicitly
        think about causality, how they would like to express their implicit
        assumptions, and what they expect language constructs describing
        conceptual models to mean. These findings informed the design of \rTisane's DSL.
        \item A benchmark comparison, a series of case studies, and a controlled
        lab study demonstrate the benefit of these DSLs in helping analysts
        author valid statistical analyses. The case studies and controlled lab
        study also show how analysts become more aware of their implicit assumptions as a result of using the DSLs.
    \end{enumerate}

    \item Formal representations and automated reasoning approaches for
    statistical analysis authoring. To support statistical testing and modeling,
    we develop representations that allow automated reasoning to compile
    conceptual specifications into statistical analyses. 
    \begin{enumerate}
        \item In \tea, we implement a constraint-based model and knowledge base
        for Null Hypothesis Significance Tests. 
        \item In \tisane, we develop an intermediate graph representation to
        summarize key conceptual assumptions and data collection details.
        Importantly, a subgraph of the representation is a causal diagram useful
        for deriving statistical models formally. 
        \item Finally, we develop an approach in \tisane and \rTisane for \textit{interactively
        compiling} high-level conceptual specifications into statistical models.
        Interfaces surface key aspects of specifications, encourage deeper reflection
        on implicit knowledge, and elicit
        clarification when needed. 
        % \polish{In a controlled lab study, we find that interactive compilation
        % contributes to analysts' increased awareness of their domain, data, and
        % statistics during data analysis.}
    \end{enumerate}
    % \item a \textbf{formal constraint-based model} to specify and select among
    % common Null Hypothesis Statistical Tests in Tea (see~\autoref{chapter:tea}); 
    % \item empirical findings of how authoring analyses requires integrating
    % conceptual, data, statistical, and programming expertise, which we summarize
    % in our \textbf{theory of hypothesis formalization} (see~\autoref{chapter:hypoForm}); 
    % \item an analysis of how the current statistical software ecosystem does not
    % explicitly support and may even hinder hypothesis formalization, suggesting
    % new \textbf{design opportunities and implications} (see~\autoref{chapter:hypoForm});
    % \item a \textbf{mixed-initiative approach} for ``interactively compiling''
    % linear models from conceptual and data relationships in Tisane; 
    % \item empirical \textbf{findings on researchers' implicit semantics of
    % conceptual models} (see~\autoref{chapter:tisane});
    % \item \textbf{new language constructs and interaction methods} for
    % reflecting on and refining conceptual models in a second version of Tisane,
    % which we call rTisane (see~\autoref{chapter:tisane}); and
    % \item qualitative and quantitative \textbf{results showing the benefit of
    % recording conceptual models and compiling them into statistical models} in
    % rTisane over a scaffolded workflow (see~\autoref{chapter:tisane}).
\end{enumerate}

% System --> Empirical --> System --> Empirical --> Empirical --> System --> Empirical 

\section{Thesis outline}
\autoref{chapter:relatedWork} covers related work that contextualizes the above
contributions. The remainder of the dissertation describes how through iterative
system development and empirical studies, we came to develop new 
DSLs, representations, and reasoning approaches for authoring
statistical analyses.

\autoref{chapter:tea} presents \tea, a DSL and runtime system for Null
Hypothesis Significance Testing (NHST). After discussing more specific related work and
explaining the rationale behind supporting NHST (\autoref{sec:relatedWorkTea}), the chapter describes a
usage scenario that illustrates how an analyst would use \tea and how it differs
from existing tools (\autoref{usageScenarioTea}), discusses key design
considerations to improve statistical testing practice
(\autoref{sec:designConsiderationsTea}), describes the DSL (\autoref{sec:TeaPL})
and constraint-based runtime system (\autoref{sec:TeaRS}), evaluates \tea
against a corpus of expert test choices and a naive test selection regime
(\autoref{sec:evalTea}), and briefly discusses the limitations and opportunities
for future work (\autoref{sec:discussionTea}). The chapter concludes with a
summary of how our work on \tea furthers the thesis of this dissertation. 

\autoref{chapter:hypoForm} introduces our theory of \hypoForm. While \tea
established the feasibility and benefits of designing a DSL focused on capturing
implicit data assumptions and hypotheses and developing a formal model of
statistical test selection, this
chapter steps back to describe data analysis more holistically. This
chapter retrospectively justifies our design in \tea and directly informs our
work on \tisane, the following chapter. \autoref{chapter:hypoForm} connects hypothesis formalization to characterizations of ``statistical
thinking'' and situates data analysis in the larger context of scientific
discovery (\autoref{sec:relatedWorkHypoForm}). The chapter proceeds to
describe a content analysis that sensitized us to key hypothesis formalization
steps (\autoref{sec:contentAnalysisHypoForm}), a lab study observing data
analysts in situ (\autoref{sec:labStudyHypoForm}), and a qualitative assessment
of existing statistical analysis tools (\autoref{sec:toolsAnalysis}). Based on
these empirical studies, we derive three design implications for how tools can
facilitate hypothesis formalization (\autoref{sec:implications}) and discuss
what problem solving strategies (and shortcuts) analysts employ without explicit
support for hypothesis formalization (\autoref{sec:discussionHypoForm}). This
chapter also concludes with a summary of how the theory of \hypoForm informs the
thesis. 

After covering related work and background on linear modeling
(\autoref{sec:relatedWorkTisane}), \autoref{chapter:tisane} describes the
\tisane DSL (\autoref{sec:tisane}) and case studies evaluating \tisane
(\autoref{sec:tisane_case_studies}). Based on researchers' feedback in the case
studies, we conclude that \tisane's DSL and interactive disambiguation process
are promising ways to assist statistical non-experts in authoring linear models.
Also, feedback on DSL language constructs motivated us to probe into how novice
analysts want to express their implicit domain knowledge and challenges they
face, which led to the following chapter.

\autoref{chapter:rTisane} is the best representation of how this dissertation
grapples with an understanding of data analysis practices (i.e., \hypoForm),
statistical methods, and empirical evidence for what analysts find usable in
order to iteratively design and evaluate a DSL and interactive disambiguation
process. \autoref{chapter:rTisane} starts with a study of how statistical
non-experts want to express their implicit domain knowledge
(\autoref{sec:exploratoryStudy}). The chapter distills key study observations
into design goals (\autoref{sec:rtisane_design_implications}) and proceeds with
system implementation details for \rTisane (\autoref{sec:rTisane}). A controlled
lab study evaluating \rTisane (\autoref{sec:summativeEval}) serves as a
summative evaluation of the key tenets of this dissertation. The chapter
concludes with key insights derived from iteratively designing and evaluating
\tisane and \rTisane as well as a few immediate next steps for improving
\rTisane based on study findings.

% \textcolor{orange}{Revisit: This chapter concludes with a
% brief discussion of the key lessons learned and limitations of \tisane (and
% \rTisane) and a summary of this work relates to the thesis.}

Finally, \autoref{chapter:conclusion} revisits the key challenges of the thesis
and how the projects in this dissertation address each
(\autoref{sec:discussionChallenges}). \autoref{chapter:conclusion} also briefly
discusses the real-world impact the DSLs developed in this dissertation have
had, offering another form of evidence in support of the thesis
(\autoref{sec:impact}). The chapter culminates with how the projects in this
dissertation create a foundation for pursuing research directions that make data
analysis authoring valid-by-design and more approachable for statistical
non-experts (\autoref{sec:futureWork}). 

% , discusses recent developments
% (\autoref{sec:recentDevelopments}), touches on the impact the systems in this
% dissertation has had in the real-world (\autoref{sec:label}),

\begin{comment}
\todo{Fill in this outline}

\section*{How to approach this dissertation} \todo{Decide if want to keep}

\section{Prior Publication and Authorship} \todo{fill in}
\end{comment}