\ej{Remove "this paper"; Rephrase the language describing code and data releases.}
\begin{flushright}
    \begin{quote}
        \textit{
        The enormous variety of modern quantitative methods leaves researchers with the
        nontrivial task of matching analysis and design to the research question.} \\ 
        \vspace{-10pt}
        \begin{flushright}
            \textit{                                 - Ronald Fisher~\cite{fisher1937design}}
        \end{flushright}
    \end{quote}
\end{flushright}
    
Since the development of modern statistical methods (e.g., Student's t-test,
ANOVA, etc.), statisticians have acknowledged the difficulty of identifying
which statistical tests people should use to answer their specific research
questions. Almost a century later, choosing appropriate statistical tests for
evaluating a hypothesis remains a challenge. As a consequence, errors in
statistical analyses are common~\cite{kaptein2012rethinking}, especially given
that data analysis has become a common task for people with little to no
statistical expertise.

A wide variety of tools (such as SPSS~\cite{wiki:spss}, SAS~\cite{wiki:sas}, and
JMP~\cite{wiki:jmp}), programming languages (e.g., R~\cite{wiki:r-language}),
and libraries (including numpy~\cite{oliphant2006numpy}, scipy~\cite{scipy}, and
statsmodels~\cite{seabold2010statsmodels}), enable people to perform specific
statistical tests, but they do not address the fundamental problem that users
may not know which statistical test to perform and how to verify that specific
assumptions about their data hold. In fact, all of these tools place the burden
of valid, replicable statistical analyses on the user and demand deep knowledge
of statistics.

Users not only have to identify their research questions, hypotheses, and domain
assumptions, but also must select statistical tests for their hypotheses (e.g.,
Student's t-test or one-way ANOVA). For each statistical test, users must be
aware of the statistical assumptions each test makes about the data (e.g.,
normality or equal variance between groups) and how to check for them, which
requires additional statistical tests (e.g., Levene's test for equal variance),
which themselves may demand further assumptions about the data. This cognitively
demanding process requires significant knowledge about statistical tests
and their preconditions as well as the ability to perform the tests and verify their
preconditions. This process can easily lead to mistakes.

In response, we design and developed Tea\footnote{named after Fisher's ``Lady
Tasting Tea'' experiment~\cite{fisher1937design}}, a high-level declarative
language for automating statistical test selection and execution that abstracts
the details of statistical analysis from the users. Tea captures users'
hypotheses and domain knowledge, translates this information into a constraint
satisfaction problem, identifies all valid statistical tests to evaluate a
hypothesis, and executes the tests. Tea's higher-level, declarative nature aims
to lower the barrier to valid, replicable analyses.

Tea is easy to integrate directly into common data analysis workflows for users
who have minimal programming experience. Tea is implemented as an open-source
Python library, so programmers can use Tea wherever they use Python, including
within Python notebooks.

In addition, Tea is flexible. Its abstraction of the analysis process and use of
a constraint solver to select tests is designed to support its extension to
emerging statistical methods, such as Bayesian analysis. Currently, Tea supports
frequentist Null Hypothesis Significance Testing (NHST).

This work makes the following contributions:
\begin{itemize}
    \item a novel DSL for automatically selecting and executing statistical
    analyses based on users' hypotheses and domain knowledge
    (\autoref{sec:TeaPL}), 
    \item a runtime system that formulates statistical test selection as a maximum constraint satisfaction problem (\autoref{sec:TeaRS}), and
    \item an initial evaluation showing that Tea can express and execute common NHST statistical tests (\autoref{sec:eval}). 
\end{itemize}

After describing related work, the chapter describes a usage scenario, providing
an overview of Tea (\autoref{sec:usagescenario}). Then, we discuss the concerns
about statistics in the HCI community that shaped Tea's
design~(\autoref{sec:design}), the implementation of
\TeaPL~(\autoref{sec:TeaPL}), the implementation of
\TeaRS~(\autoref{sec:TeaRS}), and the evaluation of Tea as a
whole~(\autoref{sec:eval}). The chapter concludes with the key limitations of
this work and a discussion of how Tea demonstrates the feasibility of my
approach central to the thesis statement(~\autoref{para:thesisStatement})

% As we found in our analysis of tools (\autoref{sec:toolsAnalysis}), a wide
% variety of tools (such as SPSS~\cite{wiki:spss}, SAS~\cite{wiki:sas}, and
% JMP~\cite{wiki:jmp}), programming languages (e.g., R~\cite{wiki:r-language}),
% and libraries (including numpy~\cite{oliphant2006numpy}, scipy~\cite{scipy}, and
% statsmodels~\cite{statsmodelsPaper}), enable people to perform specific
% statistical tests, but they do not address the fundamental problem that users
% may not know which statistical test to perform and how to verify that specific
% assumptions about their data hold. 

% To address this overlooked need, we designed Tea\footnote{named after Fisher's
% ``Lady Tasting Tea'' experiment~\cite{fisher1937design}}, a high-level
% declarative language for automating statistical test selection and execution
% that abstracts the details of statistical analysis from the users. Tea captures
% users' hypotheses and domain knowledge (\higherLevel, \connectConceptualStats),
% reformulates these into a constraint satisfaction problem, identifies all valid
% statistical tests to evaluate a hypothesis, and executes the tests. 

\input{tea/related_work.tex}

\input{tea/usage_scenario.tex}

% \section{Design of Tea's DSL}
% \section{Tea's constraint-based runtime system}
\input{tea/system.tex}

Why constraints? are they really necessary?

% \section{Evaluation:...}
\input{tea/eval.tex}

\section{Discussion: Key tensions}
- inflated alpha
- inherent tension in executing multiple statistical tests vs. sensitivity

\section{Limitations, Ongoing work, Future directions}

Great for a class of relatively simple hypotheses and research questions, but
the kinds of questions that analysts want to ask about their domain using data
are more complex that simple hypotheses. 

Testing to estimation 

NHST to statistical modeling

How do we support this larger and more complex class of use cases? Can we
generalize our approach in Tea--making implicit assumptions explicit and
automatically reasoning about these assumptions to identify valid analyses--to
statistical models? To answer this question, we set out to develop a holistic
understanding of how analysts translate research questions into statistical
analyses. 

\subsection{Ongoing development}
With teams of undergrads, I have continued to improve Tea in two specific ways. 

First, recent development has focused on updating the outputs of Tea to include
(i) interactive visualizations and (ii) text for reporting the statistical
results in the American Psychological Association's recommended formats for each
valid statistical test. The interactive visualizations aim to illustrate what
the results of the statistical tests mean, such as scatterplots for correlations
and heatmaps for the Chi-squared test. We selected the visualizations for each
test based on recommendations from Franconeri et
al.~\cite{franconeriVisualizationChooser}, what existing tools such as
JMP~\cite{jmp} already use, and our own experiences using and trying to
communicate statistical results. Development and initial user testing is on
track to wrap up by the end of spring quarter. 

Second, a usability issue with Tea's current API is its reliance of ``magic
strings.'' We are currently refactoring the API to be more object-oriented by
extending Tisane's variables data classes. We hope this revision will be more
usable with ``free'' help from existing IDEs such as VSCode that provide API
suggestions inline when specifying parameters. 

Both features will be incorporated into a new release of Tea, which I have
currently scheduled for June, 2022. 

\section{Summary of Contributions}

% Reminder: Thesis statement
% Domain-specific languages that provide abstractions for expressing conceptual
% knowledge, data collection procedures, and analysis intents instead of specific
% statistical modeling decisions coupled with automated reasoning to compile
% conceptual specifications into statistical analysis code help statistical
% non-experts more readily author valid analyses. 

A common approach to assessing support for conceptual hypotheses in data is to
use statistical tests (e.g., Student's t-test, Chi-Square test, ANOVA).
Statistical testing requires analysts to grapple with their conceptual
hypotheses, know a number of tests and when they are applicable (i.e., know the
preconditions for when these tests hold), assess the applicability of tests
(i.e., check preconditions), and pick and implement specific tests using
low-level APIs. 

Tea's key insight is that we can reformulate statistical test
selection as a constraint satisfaction problem. We designed and implemented a
higher-level DSL around this insight that takes an analyst's hypothesis and
assumptions about their data as input and provides the results of executing
valid statistical tests as output. In an evaluation, we found that Tea avoids
faulty test selection and conclusions that are easy to make using existing
tools.

Tea demonstrates the feasibility and benefit of developing systems that
emphasize \textit{higher-level abstractions} and \textit{automated reasoning}
for statistical tests (\autoref{para:thesisStatement}). However, Using
statistics to answer real-world questions requires going beyond statistical
testing to grappling with statistical modeling and effect estimation. Next, we
consider how our approach generalizes to a larger class of statistical analyses. 

\begin{comment}
% Replace the conclusion section with a summary section. Again, you should tie this chapter back to the main themes of the thesis.
4-5 sentences: 
1. Restate problem 
2. Articulate core contributions: problem/idea + technical
3. Key Evaluation results
4. 1 soundbite/takeaway
5. Transition to next chapter. 

1. Restate problem 

A common approach to assessing support for conceptual hypotheses in data is to
use statistical tests (e.g., Student's t-test, Chi-Square test, ANOVA).
Statistical testing requires analysts to grapple with their conceptual
hypotheses, know a number of tests and when they are applicable (i.e., know the
preconditions for when these tests hold), assess the applicability of tests
(i.e., check preconditions), and pick and implement specific tests using
low-level APIs. 

2. Articulate core contributions: problem/idea + technical

Tea's key insight is that we can reformulate statistical test selection as a
constraint satisfaction problem. We designed and implemented a higher-level DSL
around this insight that takes an analyst's hypothesis and assumptions about
their data as input and provides the results of executing valid statistical
tests as output. 

3. Key Evaluation results

In an evaluation, we found that Tea avoids faulty test
selection and conclusions that are easy to make using existing tools.

4. 1 soundbite/takeaway 

It is possible to design higher level language and automated reasoning to select
valid statistical tests that are widely used and even avoid faulty conclusions
that are easy to make using existing tools. The key is to make implicit
assumptions about the data explicit and reason about analyst assumptions and
computed data properties together in a logical constraint system. 

5. Transition to next chapter. 

However, an important limitation to overcome in the future chapters, most
notably in Tisane (~\autoref{chapter:tisane}) is how to generalize automated
support for more complex research questions and statistical analyses. 

Tea demonstrates the feasibility and benefit of developing systems that
emphasize \textit{higher-level abstractions} and \textit{automated reasoning}
for statistical tests (\autoref{para:thesisStatement}). Next, we consider how
this approach generalizes to a larger class of statistical analyses. could
\end{comment}

\textit{This work was done in collaboration with Maureen Daum, Jared Roesch, Sarah E.
Chasins, Emery Berger, \reneJust, and Katharina Reinecke. It was originally
published and presented at \uistConf{2019}~cite{}. Since publication, multiple
people, including most notably Shreyash Nigam, Reiden Chea, and Annie Denton,
have contributed to updating and improving Tea.}
