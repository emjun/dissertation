% Reflection: As progress through PhD research, got and grappled with how to get
% closer to users and to statistical theory in tandem.

While statistical analysis has become more pervasive among end-users who are not
statistical experts, the tools for conducting analyses have continued to require
high statistical expertise. This dissertation examines how to design and develop
tools that not only lower the barriers for statistical non-experts but also
provide guarantees about the validity of authored analyses. We introduce two new
systems, \tea and \tisane. Both provide DSLs for expressing implicit conceptual
knowledge and then compile these high-level specifications into statistical
analyses, Null Hypothesis Significance Tests in \tea (\autoref{chapter:tea}) and
generalized linear models with or without mixed effects in \tisane
(\autoref{chapter:tisane}). 
% Analysts express their implicit knowledge about
% their domain and data--as assumptions and hypotheses in Tea and conceptual
% models in Tisane--and the DSLs compile them into statistical analysis code. 
Additionally, we develop a theory of hypothesis formalization that describes the
cognitive and operational steps involved in translating a conceptual research
question into a statistical analysis implementation in code. Our theory of
hypothesis formalization retrospectively validated our design in \tea and
directly inspired the design of \tisane. 

\begin{comment}
\section{Note on methodology and implications}
Overall: Integrate systems building with formative and summative evaluations and deeper dives into understanding end-users (hypothesis formalization)
- strength of this work is moving back and forth between and integrating empirical studies with systems building
- Even within empirical studies, explored and used many qualitative and quantitative approaches
- Within systems building: Use diversity of technologies
- Identify need for methodologies in the future for designing DSLs \textit{with} end-users
\subsection{Plurality of contribution types}

A strength of this work is in how it integrates systems building with empirical
studies, both of which motivated initial methodological experiments/innovations.
We engaged in formative and summative evaluations to design, implement, iterate
on, and evaluate Tea and Tisane. The evaluations involved qualitative and
quantitative approaches. The empirical work helped
us make technical insights in how to computationally represent statistical
analysis--as constraints and as graphs. Furthermore, we took a deep dive into
triangulating the nuances involved in authoring statistical analyses through a
qualitative analysis, lab study, and tools assessment in order to develop our
theory of hypothesis formalization. 

In addition to the formal empirical studies we conducted in this dissertation,
we benefited from informal observations, reports from early users, and our
personal experiences throughout the design processes. For instance, Tea came
from years of personal experiences and informal observations of how computer
scientists author statistical analyses relying, at best, on charts and tables
describing when specific tests were applicable. 
% and a hope that there could be a more
% rigorous way to hypothesis testing.
\end{comment}

% Reflecting back on design process: 
% - Tea started with numerous personal experiences and informal observations of how computer scientists author statistical analyses
% - Started DSL design with primitives we assumed would be approachable based on survey of introductory quant methods courses. 

\begin{comment}
\section{Impact} \label{sec:label}
\ej{Fill in}
\end{comment}

\section{Discussion} \label{sec:discussionChallenges} 

This dissertation addresses three challenges central to the thesis that (i)
programming abstractions focused on capturing analysts' implicit conceptual
knowledge and (ii) formal representations and reasoning to determine statistical
analyses benefit statistical non-experts. We discuss each challenge and how the
projects in this dissertation address them below. 
% In developing programming abstractions, formal representations, and automated
% reasoning approaches for authoring statistical analyses in \tea and \tisane 

\subsection{Challenge 1: Designing the \textit{right} level of abstraction} 
With any programming language, end-users must learn and use a formalism. \tea
and \tisane provide high-level abstractions but the key to their design is that
they abstract the appropriate \textit{conceptual concerns} implicitly involved
in statistical analyses. In fact, the fact that an abstraction is high or low is
less relevant. Indeed, a key insight that guided our design of \rTisane
(\autoref{sec:rTisane}) was that analysts wanted low- and high-level conceptual
abstractions to express their domain knowledge with varying degrees of detail
that felt helpful and accurate to them (see~\autoref{sec:exploratoryStudy}).

When comparing the abstractions \tea and \tisane provide, it is easy to see that
the conceptual relationships between variables were still largely implicit in
\tea. An important takeaway from the theory of \hypoForm was the importance of
conceptual models, which are present for statistical testing and modeling alike.
Therefore, conceptual models should be a central concern in designing
programming abstractions for data analysis. 

% In this way, a direct impact of triangulating the sensemaking activities
% involved in authoring statistical analyses was to make conceptual models central
% to abstractions. 

% **Not just higher levels of abstraction but appropriate abstractions that allow analysts to dig deeper into the appropriate parts

\begin{comment}
This focus on the conceptual knowledge analysts can express and can guide
computational and statistical reasoning highlights/suggests a shift in
perspective our perspective on the design problem at hand with statistical
analysis. While much effort has been put toward making statistical computation
more precise and efficient and the mathematical abstractions expressive, the
real design barrier lies in the conceptualization of the problem of statistical
analysis. That is, statistical analysis is a means to an end for many analysts,
especially statistical non-experts. Analysts' primary goal is to understand
something about their domain. Therefore, statistical software should serve this
goal, by allowing analysts to think about their domains and goals for analysis
deeply while authoring analyses (e.g., by documenting their implicit assumptions
about their domains) and interpret the results of the analyses in light of their
conceptual domain knowledge. This view aligns with a familiar breakdown of
complex tasks into the gulfs of execution and evaluation, respectively. While
this thesis has focused on how to bridge the gulf of execution, there is much
important work on how to report and help analysts interpret the results of their
analyses in light of their conceptual assumptions and models. 
\end{comment}

% \section{Re-orienting the task we are designing for}
% Shifts the design problem on its head to view statistical analysis as a means to
% the larger end of helping analysts understand their domain better.
% Design for the purpose that statistical analysis serves. -- Norman quote?

\subsection{Challenge 2: Representing and reasoning about analysis decisions}
% abstractions that are approachable and helpful to users but **amenable to rigorous, formal reasoning**
% This dissertation argues that formal representations for reasoning about
% analysis choices is just as important as designing the appropriate programming
% abstractions. 
The abstractions that may be usable to statistical non-experts may not be
precise enough for formal reasoning (\autoref{sec:exploratoryStudy}). Therefore,
a key challenge in designing representations amenable to reasoning is in finding
a ``shared representation'' between analysts and computational techniques. Based
on \tea's key insight that statistical test selection can be reformulated as a
constraint satisfaction problem, we represented statistical tests using logical
constraints in a knowledge base. Using \tea's DSL, analysts specify additional
constraints about their hypothesis and data, which helps \tea's runtime system
solve a system of constraints to identify valid statistical tests. In \tisane,
the shared representation is the conceptual model, which \tisane represents as a
graph. This representation made reasoning about linear model formulations
straightforward by applying causal reasoning techniques on a part of the graph. 

In designing these shared representations, a temptation was to fit the DSL on
top of a reasoning approach that was straightforward. In this view, the DSL
would be a thin wrapper around the automated reasoning engine. For example, a
very early prototype of \tisane used Answer Set Programming (ASP) to define when
specific confounders should appear in a generalized linear model. In addition to
being a clunky way to represent linear model formulation rules when the
statistics community has converged on using graphs, this prototype required
analysts to incrementally refine their statistical models by interacting with
the UNSAT core. This interaction model, though interesting, did not allow us to
discovery and fully realize the real benefit of expressing conceptual models:
giving analysts an opportunity to reflect on their assumptions in an open-ended
way. 

\begin{comment}
Our experiences designing shared representations in \tea and \tisane highlight
another under-stated benefit of 

Interaction is not just for getting the system to find an answer but a way for
users to be able to not only incrementally express their intents for analysis
but also reflect and refine their understanding of the domain and data. In other
words, finding and using shared representations require designing not only the
programming abstractions but also the interactions with the abstractions. 
% , finding and using appropriate
% shared representations facilitates end-user reasoning (additional benefits). --
% maybe that's how we know we've found "appropriate" ones?

% The role of disambiguation -- not an aberration or failure of automation but
% rather a helpful, necessary part for users to be able to incrementally express
% and refine their intents for analysis.

% Benefits of separation is that we can start to introduce new statistical model/analysis inferences methods. 
\end{comment}

\subsection{Challenge 3: Interaction as reflection}
As we saw in the case studies with \tisane, providing abstractions and
interactions with shared representations for formal reasoning increases
analysts' awareness of their implicit assumptions, data, and analysis practices.
By providing the appropriate abstractions, DSLs can make the specification
process a useful form of documentation. This may later be useful for sharing and
inspection. For instance, by stating their implicit conceptual and data
assumptions in \tea and \tisane, researchers can help improve scientific
replicability and reproducibility. 
% Through their involvement in interactive compilation, 
% reify the connection between the conceptual and
% statistical in our software tools. In this way, this dissertation brings to the
% domain of data analysis, classic principles from end-user software engineering


\begin{comment}
\section{Recent developments} \label{sec:recentDevelopments}
Mention: in LLMs impact the contributions of this dissertation, exciting opportunities to leverage them to realize the goals of this work

\subsection{Construct validity: Within reach with the usage of LLMs}
This thesis focused on internal, external, and statistical conclusion validity. However, could reason about construct validity with LLMs.

\subsection{What about in the face of LLMs?}

But how do people express their domain knowledge, make the process meaningful

Mention LLMs as a technology to use here?
\end{comment}

\section{Limitations and Future work} \label{sec:futureWork}

This dissertation scrutinizes how statistical non-experts author statistical
analyses. We elaborate one some of the limitations of this work and
opportunities for future research. 

\begin{comment}
    Improving statistical analysis authoring opens up questions in
addressing core issues in statistics, end-user software engineering, programming
language design, which we hope will be additional directions other pursue. 

Some themes that emerge: 
- Support for after statistical modeling -- what do these mean? (interpretation) --> What to do next? / what would help me answer my research question? (modeling-testing) --> 
- How to capture and use these consequences into next phases of the lifecycle? 
- How could all these improve science and make data analysis more robust? 
\end{comment}

\begin{comment}
As demonstrations of how better programming abstractions and automated reasoning
can enable statistical non-experts to author analyses and improve the quality of
statistical analysis, Tea and Tisane...

Tea and Tisane have demonstrated the benefit of using higher levels of
abstraction focused on conceptual knowledge expression and reasoning. They
primarily orient the question of design...They can serve as building blocks for START HERE

Has this dissertation lost its way? Further re-orienting towards what users *really* want: to understand their domain
Push further in directions this work orients us 
- more support for understanding results, especially when some questions may not be answerable with the data/how it was collected
- knowing how robust the results are --> why not just multiverse everything?
**how do we resolve and come out from under the tyranny of false positive rates fear
\end{comment}

\subsection{Support interpretation of statistical results}
% # 4 - Support more complex queries, need help understanding the ramifications...
% While Tisane addresses the gulf of execution in authoring statistical analyses
% to answer a research question, it falls short of addressing the gulf of
% evaluation. Tisane does not yet help analysts interpret the results of their
% statistical models in light of their expressed implicit conceptual knowledge.
% For scientific discovery and decision making, accurately interpreting
% statistical results is equally important. For example, if an analysts'
% statistical results suggest that there is no evidence in the data to support the
% existence of a relationship in their conceptual model, how does the analyst make
% this interpretation? What should the analyst do about it? Is there conceptual
% model ``incorrect''? Should they revise their conceptual model? Check their data
% collection procedure? To answer these questions, there are two related
% challenges to address: (i) improved statistical reporting (What do the results
% mean?) and (ii) support for navigating consequences, such as through richer or
% follow-up queries and model revisions (What should an analyst do next?). 

While Tisane effectively addresses the gulf of execution by compiling conceptual
models into statistical models, it falls short of bridging the gulf of
evaluation. Tisane does not yet provide support for analysts to interpret the
results of their statistical models. Future research should focus on two related
challenges: (i) improving statistical reporting to enhance the understanding of
results and (ii) providing support for navigating the consequences of the
results, such as updates to analysts' conceptual models or the need to revise
statistical models.

\subsection{Connect statistical modeling and testing} 
\begin{comment}
A natural question to ask at the end of this thesis is, ``Which system should an
analyst use? Tea or Tisane?'' Tea and Tisane serve different statistical
purposes. Tea is focused on statistical testing, or finding if there is evidence
in the data for or against a specific claim, while Tisane is focused on
statistical modeling, trying to estimate the influence of a variable (or sets of
variables) on another variable, given the messy nature of the world, including
confounding, mediation, moderation, etc. Statistical testing and modeling are
not mutually exclusive. In fact, statistical experts often perform statistical
tests after building statistical models. Mathematically, all statistical tests
can be reformulated into statistical models with specific parameters of interest
serving as test statistics (see~\cite{} for an approachable summary). 

What we have observed in our studies and personal experiences is that analysts
often reach for statistical tests even when what they really need is a
statistical model. Analysts will even contort their research questions to fit
the (sub-optimal) statistical tests they can implement, just as we saw in
hypothesis formalization. 

Tea and Tisane do not address a key limitation of the current ecosystem of
statistical software, which is guidance in what analysis approach to take. A
compelling next step in this work is to allow analysts to ask follow-up queries
after authoring a statistical model to probe into what its implications are and
test the differences between groups given a model. To make this possible,
additional querying and disambiguation after outputting a statistical model from
Tisane are necessary. What would make this difficult is...
\end{comment}

A natural question arising from this dissertation is the choice between Tea and
Tisane for analysts. Tea focuses on statistical testing, determining evidence
for or against a specific claim, while Tisane emphasizes statistical modeling,
estimating variable influences in the presence of other variables (e.g.,
confounders, mediators, etc.) However, statistical testing and modeling are not
mutually exclusive. Analysts often want to conduct tests after building models
to answer substantive questions as well as assess model fit. A compelling future
direction is to enable analysts to ask follow-up questions about specific
estimates and effects from a statistical model. 

\subsection{Support more phases of the data lifecycle}
% # 5 -  What are Interfaces across the data lifecycle
% The long-view of this work...
\begin{comment}
This dissertation identifies the need for improved abstractions for authoring
statistical analyses. I argue that the appropriate abstractions should capture
the implicit domain knowledge analysts bring to their data and show the benefits
to users for doing so: valid statistical analysis formulation and increased
reflection among analysts about their domain and data. From an engineering
perspective, these abstractions allow tool designers to separate the conceptual
and statistical concerns involved in data analysis, using Tea and Tisane as
platforms for experimenting with alternative statistical model derivations and
formulations. Given that implicit assumptions about a domain pervade the entire
data lifecycle, what if we could take a similar approach throughout? What would
the appropriate data structures for capturing domain knowledge look like at each
phase? How could a new ecosystem of software tools use these representations
such that the evolution of conceptual knowledge could be tracked and traced in
meaningful ways.  -- some research questions to ask/address

A fertile area to try this integration is in connecting statistical analysis
with visual analysis
\end{comment}

This dissertation emphasizes the need for abstractions that capture analysts'
implicit domain knowledge. These abstractions enable valid analysis formulation
and promote reflective thinking. Building upon this, we can begin to ask how the
same ideas---abstractions and automated reasoning for conceptual knowledge often
implicit in statistical analyses---could apply to other phases of the data
lifecycle. Future work should explore how to elicit and track the evolution of
conceptual knowledge even before statistical analysis by developing new
elicitation techniques and representations of domain knowledge and ecosystem of
inter-operating tools to track and ensure validity throughout the data lifecycle. 

% How can software tools track and trace the
% meaningful evolution of conceptual knowledge? By tackling these questions, we
% can revolutionize data analysis and develop comprehensive tools that seamlessly
% integrate domain expertise.

\subsection{Promote analytical best practices in science}
Tea and Tisane primarily follow a top-down authoring approach, where analysts
start with a research question and hypothesis. However, as observed in our lab
study to develop hypothesis formalization (\autoref{sec:labStudyHypoForm}),
analysts often develop and refine hypotheses based on statistical results.
Therefore, a future research direction would be to develop ways to incorporate
both data-driven and research question-driven approaches to model authoring and
refinement that do not promote cherry-picking. One possibility is to leverage
\tea's and \tisane's reasoning capabilities to reason in multiple other
directions, from statistical models and data to all possible conceptual models
or statistical models to data invariants that could inform study designs.

Moreover, one of the precautions integrated into the design of Tisane was to prevent
cherry-picking and p-hacking by using analysts' conceptual models to drive
statistical model formulation. While Tisane supports mapping one conceptual
model to a statistical model, an under-explored direction is to assess the
robustness of effects across multiple possible conceptual models, especially in
cases of ambiguity or debate in a discipline. On the other hand, multiverse
analyses~\cite{} embrace conceptual model uncertainty by considering all
possible statistical model formulations. Future research should look into how to
both be consistent with aspects of conceptual models researchers know and assess
evidence for other competing aspects of conceptual models.


% \subsection{Improve science}
% #7 - How can this approach improve science? 
\begin{comment}
The systems in this dissertation show a way to author valid statistical analyses
by design. Tea incorporates formal methods to statistical test selection, and
Tisane incorporates causal reasoning into model authoring. These efforts are in
contrast to existing systems that place the burden of validity on end-users.
These systems are a step from threats to validity to guarantees about validity. 

To truly improve the quality and reliability of science, a more end-to-end
approach, even before statistical authoring, is important to design for.
Recently, researchers have used Tea to support study planning and
pre-registration~\cite{rock}. However, support for identifying interesting
research questions and hypotheses in addition to planning experiments and data
collection methods, would help. This is possible given that we can treat these
reasoning engines to reason in multiple directions, from hypotheses to
statistical models or statistical models to hypotheses, research questions, and
assumptions about data. Could even incorporate some data insights (e.g.,
structure learning). 
Tea and Tisane focus on a top-down authoring approach where analysts start with
a research question and hypothesis. However, as we saw in hypothesis
formalization, analysts may refine their hypotheses in response to statistical
results. Therefore, incorporating both data-driven and research question-driven
approaches to model authoring and refinement will be an important next step. To
do so, need to support interpretation and refinement. 

One of the precautions we designed Tisane around was preventing
cherry-picking and p-hacking by involving analysts in the statistical model
formulation process.
Tisane supports one conceptual model to a statistical model. However, to assess
robustness of an effect, across multiple possible conceptual models or where
there is ambiguity, analysts might need to consider multiple possible conceptual
models. We did this by having analysts pick one final model, but there could be
ways to further embrace the uncertainty in conceptual models and statistical
model formulations by authoring a multiverse of statistical models to measure
the robustness of statistical results. By reporting out the sensitivity of a
result, could address cherry-picking concerns. 


An interesting observation we made in our lab study to develop hypothesis
formalization was an insistence on being ``data-driven,'' which meant refusing
to state implicit assumptions explicitly.
\end{comment}

% Formal methods for science
% E.g., github for scientific checking 


% Reproducibility -- something we wanted to touch on Tea and Tisane

% In other words, what would it look like to capture and track domain knowledge
% throughout in an ecosystem of software tools that facilitated expression and
% reasoning about conceptual knowledge. This conceptual knowledge may not be
% graphical prior to data analysis or collection, but perhaps knowledge graphs
% could capture some important aspects? 

% documenting, and sharing

% \subsection{The long view: Ecosystem of software tools and computational reasoning throughout the data lifecycle}
\begin{comment}
The systems developed in this dissertation demonstrate a deliberate approach to
authoring valid statistical analyses. Tea incorporates formal methods for
statistical test selection, while Tisane incorporates causal reasoning into
model authoring. These systems differ from existing approaches that place the
burden of ensuring validity on end-users, representing a shift from threats to
validity to guarantees of validity.

Paragraph 2: To truly enhance the quality and reliability of scientific
research, it is crucial to adopt a more comprehensive, end-to-end approach that
extends beyond statistical authoring. 
\end{comment}

\begin{comment}
\subsection{Methods for human-centered programming language design}
% # 6 - 
From Tea to Tisane, we changed how we designed DSL primitives. To identify
primitives in Tea's DSL, we surveyed two introductory quantitative methods
courses in human-computer interaction. For Tisane, we started by iterating on
primitives that made sense to us, as designers, and would be amenable to formal
reasoning. However, between the first and second releases, we sought to further
incorporate what analysts want to express to increase the likelihood of them
using the system correctly. In this process, we sought to strike the right
balance between designer and end-user participatory design. While general
approaches for ``end-user programming'' have been developed, such as in
PLIERS~\cite{}, there are not yet methods for how to adapt DSLs over time.
Recent work on Stitch~\cite{} finds ways to improve DSLs through data on API
usage. This is a promising direction, and earlier ways to prototype APIs with
end-users with a similar flavor could be helpful. 

Methods for specializing DSLs are also promising/important.

need for human-centered methods to design DSLs
\end{comment}

\section{Improving data science education}

1 sentence: Motivation: From conversations with students and my own experience taking statistics courses
throughout undergraduate and graduate education is that the connection between
statistical methods and the kinds of questions I want to ask is often unclear.
Furthermore, students feel they need to memorize a bunch of different methods,
at the cost of thinking through what their substantive questions are and what
they should care about in a statistical approach. 

2: Goal, Impact: Promote statistical thinking, an essential component of practicing data science. 

Especially, greatest potential: Especially to teach students to separate
multiple sets of concerns, specifically the conceptual from the statsitical 

3. Role of systems: Use \tea and \tisane to focus students to focus first on identifying and
articulating their motivation and intents for analysis 

Before introducing and teaching statistical details

4. Future work: Deploy \tea and \tisane 
- questions to answer: impact on statistical thinking, computational thinking 
- what additional tools are necessary to develop? 

A ramp from novice to expert
tools is missing in the current ecosystem~\cite{mcnamara2018keyAttributes}. Tea
and Tisane lay the foundation for a bridge between novice and expert tools by
providing abstractions that match those of statistical non-experts while also
giving experts control, flexibility, and compatibility with other expert tools
in Python and R. While pursuing the above research agenda, I look forward to
directly improving data science courses I teach by deploying my systems in the
classroom, discovering students' needs, and iterating on tools and curriculum.
In pursuing this goal, I want to ease
transitions between analysis paradigms (e.g., NHST and Bayesian inference). One
promising direction is to separate concerns about model specification from
interpretation and assessment. 


Get rid of?: In a small way, this separation also teaches students how to separate
specification from implementation, an essential perspective in computer science.
So that if students need to implement more complex analyses, they have some
awareness of how to organize their computational approach. 


\section{Impact}
The most rewarding part of conducting the work in this dissertation has been to
see real-world use cases and adoption of tools. As of May 2023, \tea has been
downloaded 15K times, and the first release of \tisane has been downloaded 12K
times. Over the last few years, I have also enjoyed reading and answering a
flurry of emails where analysts, including scientists and social scientists,
share anecdotes of how they have used (and sometimes failed to use) \tea and
\tisane.

\ej{Add IHME anecdote/story/example?}

To more systematically capture and act on these kinds of anecdotes in the
future, I am excited to develop a web platform for \tea and \tisane, where users
can share their programs, data, and insights. Over time, I hope to collect a
gallery of examples to answer questions about challenges using the DSLs, the
learn which use cases are under-supported, and assess the practical impact of
using conceptual abstractions and automated reasoning. I would also like to see
if end-users repeatedly use \tea and \tisane or if these are one-off
engagements. I look forward to not only pursuing ideas and systems developed in
this dissertation but also fostering a community of users. 
% who can not only inform future research but also benefit from future systems. 

% Also future opportunities for deploying and testing a community of users 

\section{Closing Remarks}

designed and implemented two systems, Tea~\cite{jun2019tea} and
Tisane~\cite{jun2022tisane}, that leverage \textbf{domain-specific languages}
(DSLs) to capture analysts' implicit assumptions and conceptual knowledge. Users
\textbf{interactively compile} these high-level specifications into low-level
code. To infer valid statistical analyses, the systems \textbf{programmatically
represent and reason about core statistical authoring challenges} as constraints
and graphs.% (\autoref{fig:tools}).
As a result, my systems prevent common analysis
mistakes~\cite{jun2019tea,jun2022tisane}. 