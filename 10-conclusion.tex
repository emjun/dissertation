% Reflection: As progress through PhD research, got and grappled with how to get
% closer to users and to statistical theory in tandem.

While statistical analysis has become more pervasive among end-users who are not
statistical experts, the tools for conducting analyses have continued to require
high statistical expertise. This dissertation examines how to design and develop
tools that not only lower the barriers for statistical non-experts but also
provide guarantees about the validity of authored analyses. We introduce two new
systems, \tea and \tisane. Both provide DSLs for expressing implicit conceptual
knowledge and then compile these high-level specifications into statistical
analyses, Null Hypothesis Significance Tests in \tea (\autoref{chapter:tea}) and
generalized linear models with or without mixed effects in \tisane
(\autoref{chapter:tisane}). 
% Analysts express their implicit knowledge about
% their domain and data--as assumptions and hypotheses in Tea and conceptual
% models in Tisane--and the DSLs compile them into statistical analysis code. 
Additionally, we develop a theory of hypothesis formalization that describes the
cognitive and operational steps involved in translating a conceptual research
question into a statistical analysis implementation in code. Our theory of
hypothesis formalization retrospectively validated our design in \tea and
directly inspired the design of \tisane. 

\begin{comment}
\section{Note on methodology and implications}
Overall: Integrate systems building with formative and summative evaluations and deeper dives into understanding end-users (hypothesis formalization)
- strength of this work is moving back and forth between and integrating empirical studies with systems building
- Even within empirical studies, explored and used many qualitative and quantitative approaches
- Within systems building: Use diversity of technologies
- Identify need for methodologies in the future for designing DSLs \textit{with} end-users
\subsection{Plurality of contribution types}

A strength of this work is in how it integrates systems building with empirical
studies, both of which motivated initial methodological experiments/innovations.
We engaged in formative and summative evaluations to design, implement, iterate
on, and evaluate Tea and Tisane. The evaluations involved qualitative and
quantitative approaches. The empirical work helped
us make technical insights in how to computationally represent statistical
analysis--as constraints and as graphs. Furthermore, we took a deep dive into
triangulating the nuances involved in authoring statistical analyses through a
qualitative analysis, lab study, and tools assessment in order to develop our
theory of hypothesis formalization. 

In addition to the formal empirical studies we conducted in this dissertation,
we benefited from informal observations, reports from early users, and our
personal experiences throughout the design processes. For instance, Tea came
from years of personal experiences and informal observations of how computer
scientists author statistical analyses relying, at best, on charts and tables
describing when specific tests were applicable. 
% and a hope that there could be a more
% rigorous way to hypothesis testing.
\end{comment}

% Reflecting back on design process: 
% - Tea started with numerous personal experiences and informal observations of how computer scientists author statistical analyses
% - Started DSL design with primitives we assumed would be approachable based on survey of introductory quant methods courses. 

\begin{comment}
\section{Impact} \label{sec:label}
\ej{Fill in}
\end{comment}

\section{Discussion} \label{sec:discussionChallenges} 

This dissertation addresses three challenges central to the thesis that (i)
programming abstractions focused on capturing analysts' implicit conceptual
knowledge and (ii) formal representations and reasoning to determine statistical
analyses benefit statistical non-experts. We discuss each challenge and how the
projects in this dissertation address them below. 
% In developing programming abstractions, formal representations, and automated
% reasoning approaches for authoring statistical analyses in \tea and \tisane 

\subsection{Challenge 1: Designing the \textit{right} level of abstraction} 
With any programming language, end-users must learn and use a formalism. \tea
and \tisane provide high-level abstractions but the key to their design is that
they abstract the appropriate \textit{conceptual concerns} implicitly involved
in statistical analyses. In fact, the fact that an abstraction is high or low is
less relevant. Indeed, a key insight that guided our design of \rTisane
(\autoref{sec:rTisane}) was that analysts wanted low- and high-level conceptual
abstractions to express their domain knowledge with varying degrees of detail
that felt helpful and accurate to them (see~\autoref{sec:exploratoryStudy}).

When comparing the abstractions \tea and \tisane provide, it is easy to see that
the conceptual relationships between variables were still largely implicit in
\tea. An important takeaway from the theory of \hypoForm was the importance of
conceptual models, which are present for statistical testing and modeling alike.
Therefore, conceptual models should be a central concern in designing
programming abstractions for data analysis. 

% In this way, a direct impact of triangulating the sensemaking activities
% involved in authoring statistical analyses was to make conceptual models central
% to abstractions. 

% **Not just higher levels of abstraction but appropriate abstractions that allow analysts to dig deeper into the appropriate parts

\begin{comment}
This focus on the conceptual knowledge analysts can express and can guide
computational and statistical reasoning highlights/suggests a shift in
perspective our perspective on the design problem at hand with statistical
analysis. While much effort has been put toward making statistical computation
more precise and efficient and the mathematical abstractions expressive, the
real design barrier lies in the conceptualization of the problem of statistical
analysis. That is, statistical analysis is a means to an end for many analysts,
especially statistical non-experts. Analysts' primary goal is to understand
something about their domain. Therefore, statistical software should serve this
goal, by allowing analysts to think about their domains and goals for analysis
deeply while authoring analyses (e.g., by documenting their implicit assumptions
about their domains) and interpret the results of the analyses in light of their
conceptual domain knowledge. This view aligns with a familiar breakdown of
complex tasks into the gulfs of execution and evaluation, respectively. While
this thesis has focused on how to bridge the gulf of execution, there is much
important work on how to report and help analysts interpret the results of their
analyses in light of their conceptual assumptions and models. 
\end{comment}

% \section{Re-orienting the task we are designing for}
% Shifts the design problem on its head to view statistical analysis as a means to
% the larger end of helping analysts understand their domain better.
% Design for the purpose that statistical analysis serves. -- Norman quote?

\subsection{Challenge 2: Representing and reasoning about analysis decisions}
% abstractions that are approachable and helpful to users but **amenable to rigorous, formal reasoning**
% This dissertation argues that formal representations for reasoning about
% analysis choices is just as important as designing the appropriate programming
% abstractions. 
The abstractions that may be usable to statistical non-experts may not be
precise enough for formal reasoning (\autoref{sec:exploratoryStudy}). Therefore,
a key challenge in designing representations amenable to reasoning is in finding
a ``shared representation'' between analysts and computational techniques. Based
on \tea's key insight that statistical test selection can be reformulated as a
constraint satisfaction problem, we represented statistical tests using logical
constraints in a knowledge base. Using \tea's DSL, analysts specify additional
constraints about their hypothesis and data, which helps \tea's runtime system
solve a system of constraints to identify valid statistical tests. In \tisane,
the shared representation is the conceptual model, which \tisane represents as a
graph. This representation made reasoning about linear model formulations
straightforward by applying causal reasoning techniques on a part of the graph. 

In designing these shared representations, a temptation was to fit the DSL on
top of a reasoning approach that was straightforward. In this view, the DSL
would be a thin wrapper around the automated reasoning engine. For example, a
very early prototype of \tisane used Answer Set Programming (ASP) to define when
specific confounders should appear in a generalized linear model. In addition to
being a clunky way to represent linear model formulation rules when the
statistics community has converged on using graphs, this prototype required
analysts to incrementally refine their statistical models by interacting with
the UNSAT core. This interaction model, though interesting, did not allow us to
discovery and fully realize the real benefit of expressing conceptual models:
giving analysts an opportunity to reflect on their assumptions in an open-ended
way. 

\begin{comment}
Our experiences designing shared representations in \tea and \tisane highlight
another under-stated benefit of 

Interaction is not just for getting the system to find an answer but a way for
users to be able to not only incrementally express their intents for analysis
but also reflect and refine their understanding of the domain and data. In other
words, finding and using shared representations require designing not only the
programming abstractions but also the interactions with the abstractions. 
% , finding and using appropriate
% shared representations facilitates end-user reasoning (additional benefits). --
% maybe that's how we know we've found "appropriate" ones?

% The role of disambiguation -- not an aberration or failure of automation but
% rather a helpful, necessary part for users to be able to incrementally express
% and refine their intents for analysis.

% Benefits of separation is that we can start to introduce new statistical model/analysis inferences methods. 
\end{comment}

\subsection{Challenge 3: Interaction as reflection}
As we saw in the case studies with \tisane, providing abstractions and
interactions with shared representations for formal reasoning increases
analysts' awareness of their implicit assumptions, data, and analysis practices.
By providing the appropriate abstractions, DSLs can make the specification
process a useful form of documentation. This may later be useful for sharing and
inspection. For instance, by stating their implicit conceptual and data
assumptions in \tea and \tisane, researchers can help improve scientific
replicability and reproducibility. 
% Through their involvement in interactive compilation, 
% reify the connection between the conceptual and
% statistical in our software tools. In this way, this dissertation brings to the
% domain of data analysis, classic principles from end-user software engineering


\begin{comment}
\section{Recent developments} \label{sec:recentDevelopments}
\ej{Do this during revisions?}

\subsection{Construct validity: Within reach with the usage of LLMs}
This thesis focused on internal, external, and statistical conclusion validity. However, could reason about construct validity with LLMs.

\subsection{What about in the face of LLMs?}

But how do people express their domain knowledge, make the process meaningful

Mention LLMs as a technology to use here?
\end{comment}

\section{Limitations and Future work} \label{sec:futureWork}
Some themes that emerge: 
- Support for after statistical modeling -- what do these mean? (interpretation) --> What to do next? / what would help me answer my research question? (modeling-testing) --> 
- How to capture and use these consequences into next phases of the lifecycle? 
- How could all these improve science and make data analysis more robust? 


% #8  : Summarize future directions

% This dissertation presents two systems, Tea and Tisane, that demonstrate how
% statistical software can guarantee statistical analysis validity by design. They
% provide programming abstractions focused on gathering implicit conceptual knowledge. 

By addressing the important trend of the increased diversity of end-users
authoring statistical analyses and the importance of correct analyses, this
dissertation opens up statistical analysis authoring as a domain for further
research. 

This dissertation dissects statistical data analysis from an activity taken for
granted into a process fraught with problems for end-users that have high impact
consequences. Improving statistical analysis authoring opens up questions in
addressing core issues in statistics, end-user software engineering, programming
language design, which we hope will be additional directions other pursue. Here
we elaborate one some of the limitations of this work and opportunities for
future research in each of these disciplines. 

\begin{comment}
As demonstrations of how better programming abstractions and automated reasoning
can enable statistical non-experts to author analyses and improve the quality of
statistical analysis, Tea and Tisane...

Tea and Tisane have demonstrated the benefit of using higher levels of
abstraction focused on conceptual knowledge expression and reasoning. They
primarily orient the question of design...They can serve as building blocks for START HERE

Has this dissertation lost its way? Further re-orienting towards what users *really* want: to understand their domain
Push further in directions this work orients us 
- more support for understanding results, especially when some questions may not be answerable with the data/how it was collected
- knowing how robust the results are --> why not just multiverse everything?
**how do we resolve and come out from under the tyranny of false positive rates fear
\end{comment}

\subsection{Connecting modeling with testing} 
% #3 - 1 paragraph (5 sentences)
A natural question to ask at the end of this thesis is, ``Which system should an
analyst use? Tea or Tisane?'' Tea and Tisane serve different statistical
purposes. Tea is focused on statistical testing, or finding if there is evidence
in the data for or against a specific claim, while Tisane is focused on
statistical modeling, trying to estimate the influence of a variable (or sets of
variables) on another variable, given the messy nature of the world, including
confounding, mediation, moderation, etc. Statistical testing and modeling are
not mutually exclusive. In fact, statistical experts often perform statistical
tests after building statistical models. Mathematically, all statistical tests
can be reformulated into statistical models with specific parameters of interest
serving as test statistics (see~\cite{} for an approachable summary). 

What we have observed in our studies and personal experiences is that analysts
often reach for statistical tests even when what they really need is a
statistical model. Analysts will even contort their research questions to fit
the (sub-optimal) statistical tests they can implement, just as we saw in
hypothesis formalization. 

Tea and Tisane do not address a key limitation of the current ecosystem of
statistical software, which is guidance in what analysis approach to take. A
compelling next step in this work is to allow analysts to ask follow-up queries
after authoring a statistical model to probe into what its implications are and
test the differences between groups given a model. To make this possible,
additional querying and disambiguation after outputting a statistical model from
Tisane are necessary. What would make this difficult is...

\subsection{Interpretation of results}
% # 4 - Support more complex queries, need help understanding the ramifications...
While Tisane addresses the gulf of execution in authoring statistical analyses
to answer a research question, it falls short of addressing the gulf of
evaluation. Tisane does not yet help analysts interpret the results of their
statistical models in light of their expressed implicit conceptual knowledge.
For scientific discovery and decision making, accurately interpreting
statistical results is equally important. For example, if an analysts'
statistical results suggest that there is no evidence in the data to support the
existence of a relationship in their conceptual model, how does the analyst make
this interpretation? What should the analyst do about it? Is there conceptual
model ``incorrect''? Should they revise their conceptual model? Check their data
collection procedure? To answer these questions, there are two related
challenges to address: (i) improved statistical reporting (What do the results
mean?) and (ii) support for navigating consequences, such as through richer or
follow-up queries and model revisions (What should an analyst do next?). 


rTisane: Linear model that would help assess the average causal effect of the IV of
interest. However, do not output the actual effect. Assume that if the IV is  of
interest, analysts are likely to be interested in its average influence on the
outcome.

Furthermore, in the long-term, to support more complex analyses, there is a need
to support more types of analyses. 

Tea does this a bit better. 

\subsection{Support throughout the data lifecycle}
% # 5 -  What are Interfaces across the data lifecycle
% The long-view of this work...

This dissertation identifies the need for improved abstractions for authoring
statistical analyses. I argue that the appropriate abstractions should capture
the implicit domain knowledge analysts bring to their data and show the benefits
to users for doing so: valid statistical analysis formulation and increased
reflection among analysts about their domain and data. From an engineering
perspective, these abstractions allow tool designers to separate the conceptual
and statistical concerns involved in data analysis, using Tea and Tisane as
platforms for experimenting with alternative statistical model derivations and
formulations. Given that implicit assumptions about a domain pervade the entire
data lifecycle, what if we could take a similar approach throughout? What would
the appropriate data structures for capturing domain knowledge look like at each
phase? How could a new ecosystem of software tools use these representations
such that the evolution of conceptual knowledge could be tracked and traced in
meaningful ways.  -- some research questions to ask/address

A fertile area to try this integration is in connecting statistical analysis with visual analysis

\subsection{Improving science}
% #7 - How can this approach improve science? 
The systems in this dissertation show a way to author valid statistical analyses
by design. Tea incorporates formal methods to statistical test selection, and
Tisane incorporates causal reasoning into model authoring. These efforts are in
contrast to existing systems that place the burden of validity on end-users.
These systems are a step from threats to validity to guarantees about validity. 

% Incorporate data-driven approaches 
To truly improve the quality and reliability of science, a more end-to-end
approach, even before statistical authoring, is important to design for.
Recently, researchers have used Tea to support study planning and
pre-registration~\cite{rock}. However, support for identifying interesting
research questions and hypotheses in addition to planning experiments and data
collection methods, would help. This is possible given that we can treat these
reasoning engines to reason in multiple directions, from hypotheses to
statistical models or statistical models to hypotheses, research questions, and
assumptions about data. Could even incorporate some data insights (e.g.,
structure learning). 
Tea and Tisane focus on a top-down authoring approach where analysts start with
a research question and hypothesis. However, as we saw in hypothesis
formalization, analysts may refine their hypotheses in response to statistical
results. Therefore, incorporating both data-driven and research question-driven
approaches to model authoring and refinement will be an important next step. To
do so, need to support interpretation and refinement. 

One of the precautions we designed Tisane around was preventing
cherry-picking and p-hacking by involving analysts in the statistical model
formulation process.
Tisane supports one conceptual model to a statistical model. However, to assess
robustness of an effect, across multiple possible conceptual models or where
there is ambiguity, analysts might need to consider multiple possible conceptual
models. We did this by having analysts pick one final model, but there could be
ways to further embrace the uncertainty in conceptual models and statistical
model formulations by authoring a multiverse of statistical models to measure
the robustness of statistical results. By reporting out the sensitivity of a
result, could address cherry-picking concerns. 


An interesting observation we made in our lab study to develop hypothesis
formalization was an insistence on being ``data-driven,'' which meant refusing
to state implicit assumptions explicitly.


Formal methods for science
E.g., github for scientific checking 

% Reproducibility -- something we wanted to touch on Tea and Tisane

% In other words, what would it look like to capture and track domain knowledge
% throughout in an ecosystem of software tools that facilitated expression and
% reasoning about conceptual knowledge. This conceptual knowledge may not be
% graphical prior to data analysis or collection, but perhaps knowledge graphs
% could capture some important aspects? 

% documenting, and sharing

% \subsection{The long view: Ecosystem of software tools and computational reasoning throughout the data lifecycle}


\subsection{Methods for human-centered programming language design}
% # 6 - 
From Tea to Tisane, we changed how we designed DSL primitives. To identify
primitives in Tea's DSL, we surveyed two introductory quantitative methods
courses in human-computer interaction. For Tisane, we started by iterating on
primitives that made sense to us, as designers, and would be amenable to formal
reasoning. However, between the first and second releases, we sought to further
incorporate what analysts want to express to increase the likelihood of them
using the system correctly. In this process, we sought to strike the right
balance between designer and end-user participatory design. While general
approaches for ``end-user programming'' have been developed, such as in
PLIERS~\cite{}, there are not yet methods for how to adapt DSLs over time.
Recent work on Stitch~\cite{} finds ways to improve DSLs through data on API
usage. This is a promising direction, and earlier ways to prototype APIs with
end-users with a similar flavor could be helpful. 

Methods for specializing DSLs are also promising/important.

need for human-centered methods to design DSLs

\section{Closing Remarks}
\ej{Fill in after intro} 